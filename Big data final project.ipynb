{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e740879-5177-42e9-ba0d-617e52c0ea43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "markdown"
    }
   },
   "source": [
    "# MADSC102-MUC07322 Final Exam Project: End-to-End Data Analytics on Databricks\n",
    "\n",
    "**Student Name: VENKAT SAI MOTHE\n",
    "**Date:** 14/12/2025\n",
    "**Platform:** Databricks\n",
    "**Data Source:** Kaggle CSV File (Online Retail Dataset)\n",
    "\n",
    "\n",
    "## Public CSV Link\n",
    "Using the following public URL to access the dataset for structured ingestion:\n",
    "\n",
    "**CSV URL:** `https://files.manuscdn.com/user_upload_by_module/session_file/310419663030150399/rsxNxRySzwJGsLbc.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78f0a958-8117-4e20-8ef2-f97eba3be328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "markdown"
    }
   },
   "source": [
    "## Phase 1: Data Ingestion (CSV)\n",
    "\n",
    "We will load the 'Online Retail' CSV file directly from the public URL into a PySpark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ec68c4d-d7b9-43e4-a235-fa8e29166c1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "python"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, when, regexp_replace, trim, to_timestamp\n",
    "\n",
    "CSV_URL = \"https://files.manuscdn.com/user_upload_by_module/session_file/310419663030150399/rsxNxRySzwJGsLbc.csv\"\n",
    "\n",
    "raw_df = spark.read.csv(\n",
    "    CSV_URL,\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\" \n",
    ")\n",
    "\n",
    "print(f\"Raw DataFrame loaded with {raw_df.count()} records.\")\n",
    "raw_df.printSchema()\n",
    "display(raw_df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5d64f0e-0edf-42a2-b24d-fa4690e85aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "markdown"
    }
   },
   "source": [
    "## Phase 2: Data Cleaning, Preparation, and Delta Storage\n",
    "\n",
    "We will perform cleaning by:\n",
    "1.  Filtering out cancelled transactions (InvoiceNo starting with 'C').\n",
    "2.  Dropping rows with missing CustomerID (required for customer analysis).\n",
    "3.  Calculating a new `Sales` column (`Quantity * UnitPrice`).\n",
    "4.  Casting `InvoiceDate` to a proper timestamp format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52463673-31e5-4e50-b10c-213293571a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned = raw_df.filter(~col(\"InvoiceNo\").startswith(\"C\")) \\\n",
    "                     .filter(col(\"CustomerID\").isNotNull())\n",
    "\n",
    "df_final = df_cleaned.withColumn(\"Sales\", col(\"Quantity\") * col(\"UnitPrice\")) \\\n",
    "                     .withColumn(\"InvoiceTimestamp\", to_timestamp(col(\"InvoiceDate\"), \"M/d/yyyy H:mm\")) \\\n",
    "                     .select(\n",
    "                         col(\"InvoiceNo\"),\n",
    "                         col(\"StockCode\"),\n",
    "                         trim(col(\"Description\")).alias(\"Description\"), \n",
    "                         col(\"Quantity\"),\n",
    "                         col(\"InvoiceTimestamp\").alias(\"InvoiceDate\"),\n",
    "                         col(\"UnitPrice\"),\n",
    "                         col(\"CustomerID\"),\n",
    "                         col(\"Country\"),\n",
    "                         col(\"Sales\")\n",
    "                     )\n",
    "\n",
    "print(f\"Cleaned DataFrame has {df_final.count()} records.\")\n",
    "df_final.printSchema()\n",
    "display(df_final.limit(5))\n",
    "\n",
    "DATABASE_NAME = \"final_exam_db\"\n",
    "TABLE_NAME = \"online_retail_data\"\n",
    "\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME}\")\n",
    "\n",
    "df_final.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"{DATABASE_NAME}.{TABLE_NAME}\")\n",
    "\n",
    "print(f\"Data successfully written to Delta table: {DATABASE_NAME}.{TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16a97579-e87e-4e40-9e31-b265fbc04a9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Phase 3: SQL Analysis (for Dashboarding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bea98f66-e3c9-4bc9-be64-3a4aa5d59708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  Description,\n",
    "  SUM(Sales) AS TotalSales\n",
    "FROM\n",
    "  final_exam_db.online_retail_data\n",
    "GROUP BY\n",
    "  Description\n",
    "ORDER BY\n",
    "  TotalSales DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2089227-674c-408d-bc21-c850d0004d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  Country,\n",
    "  SUM(Sales) AS TotalSales,\n",
    "  COUNT(DISTINCT CustomerID) AS UniqueCustomers\n",
    "FROM\n",
    "  final_exam_db.online_retail_data\n",
    "GROUP BY\n",
    "  Country\n",
    "ORDER BY\n",
    "  TotalSales DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  DATE_FORMAT(InvoiceDate, 'yyyy-MM') AS YearMonth,\n",
    "  SUM(Sales) AS MonthlySalesRevenue,\n",
    "  COUNT(DISTINCT InvoiceNo) AS OrderVolume\n",
    "FROM final_exam_db.online_retail_data\n",
    "GROUP BY DATE_FORMAT(InvoiceDate, 'yyyy-MM')\n",
    "ORDER BY YearMonth;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  Country,\n",
    "  ROUND(SUM(Sales) / COUNT(DISTINCT CustomerID), 2) AS AvgSalesPerCustomer\n",
    "FROM final_exam_db.online_retail_data\n",
    "GROUP BY Country\n",
    "ORDER BY AvgSalesPerCustomer DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  Country,\n",
    "  COUNT(*) AS TotalTransactions\n",
    "FROM final_exam_db.online_retail_data\n",
    "GROUP BY Country\n",
    "ORDER BY TotalTransactions DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "221f5672-cfa3-407d-a72d-52f6b2c3c1b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "markdown"
    }
   },
   "source": [
    "## Phase 4: Notebook Analysis (PySpark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b911429-0b41-4815-9830-d3a12472685a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "python"
    }
   },
   "outputs": [],
   "source": [
    "retail_df = spark.table(\"final_exam_db.online_retail_data\")\n",
    "print(\"Loaded Delta table for analysis.\")\n",
    "\n",
    "print(\"\\nDescriptive Statistics for Quantity, UnitPrice, and Sales:\")\n",
    "retail_df.select('Quantity', 'UnitPrice', 'Sales').describe().show()\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "top_customers = retail_df.groupBy(\"CustomerID\") \\\n",
    "                         .agg(sum(\"Sales\").alias(\"TotalSpend\")) \\\n",
    "                         .orderBy(col(\"TotalSpend\").desc())\n",
    "\n",
    "print(\"\\nTop 5 Customers by Total Spend:\")\n",
    "display(top_customers.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a57f56c-bc4e-4e4b-8487-745be7ea52d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "databricks": {
     "language": "markdown"
    }
   },
   "source": [
    "## Phase 5: Dashboard Instructions\n",
    "\n",
    "**Note:** The actual Databricks SQL Dashboard must be created in the Databricks workspace outside of this notebook. \n",
    "\n",
    "**Instructions for Dashboard Creation:**\n",
    "\n",
    "1.  **Create SQL Queries:** Save the two SQL queries from Phase 3 as Databricks SQL Queries (e.g., `Q1_Top_10_Products` and `Q2_Sales_by_Country`).\n",
    "2.  **Create Dashboard:** Create a new Databricks SQL Dashboard.\n",
    "3.  **Add Visualizations:**\n",
    "    *   Use `Q1_Top_10_Products` to create a **Bar Chart** (X-axis: `Description`, Y-axis: `TotalSales`).\n",
    "    *   Use `Q2_Sales_by_Country` to create a **Map Visualization** or a **Pie Chart** (Group by: `Country`, Value: `TotalSales`).\n",
    "4.  **Add Filters:** Add a **Text Parameter** filter to the dashboard linked to the `Country` column in the underlying table to allow filtering of the data."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "final_exam_project",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
